version: 2.1

jobs:
  build:
    parameters:
      build-image:
        type: string
      nginx-tag:
        type: string
    docker:
    - image:  << parameters.build-image >>
    resource_class: xlarge
    environment:
      # The `resource_class` implies a memory limit and supposedly a CPU count
      # limit.  However, either there is no actual CPU count limit, or the
      # limit cannot be determined from within the running job.
      # Instead, the number of CPUs on the host machine is all we can see.
      # This means that a command like `make --jobs=$(nproc)` is likely to run
      # out of memory, because while the `resource_class` says it has 2 CPUs,
      # `nproc` will report something like 36.  `make` will then spawn a bunch
      # of processes, and the job will run out of memory.
      # So, here we hard-code the number of CPUs supposedly offered by the
      # `resource_class`.  For information about the `resource_class` values,
      # see:
      # https://circleci.com/docs/2.0/configuration-reference/
      MAKE_JOB_COUNT: 8
    steps:
    - checkout
    - run: printf << parameters.nginx-tag >> >nginx-tag
    - run: make build
    - persist_to_workspace:
        root: .
        paths:
          - .build/libngx_http_datadog_module.so
          - nginx-tag
    - store_artifacts:
        path: .build/libngx_http_datadog_module.so
        destination: ngx_http_datadog_module.so

  test:
    docker:
    - image: cimg/python:3.10.5
    environment:
      # See https://github.com/containers/podman/issues/13889
      DOCKER_BUILDKIT: 0
    steps:
    - checkout
    - attach_workspace:
        at: /tmp/workspace
    - run: mv /tmp/workspace/nginx-tag .
    - run: mv /tmp/workspace/.build/libngx_http_datadog_module.so test/services/nginx/ngx_http_datadog_module.so
    - setup_remote_docker:
        # Cache docker layers somewhere so that we don't have to rebuild test
        # service images every time.
        docker_layer_caching: true
    - run: "env | sort"
    # Instead of just running the tests, we run the tests and note whether they
    # succeeded.  This way, we can save the verbose output afterward and then
    # fail if the tests didn't succeed.
    # TODO: This sucks, though.  Find a better way.  The output of a failed test
    # runner should be red in the CI interface.
    - run: |
        if test/bin/run --verbose; then
          touch .tests-succeeded
        fi
    - store_artifacts:
        path: test/logs/test.log
        destination: test.log
    - run: |
        if ! [ -f .tests-succeeded ]; then
          cat test/logs/test.log
          printf '\n\nTests failed.  See the test run step for test driver output.  Verbose output is above.\n'
          exit 1
        fi

workflows:
  build-and-test-all:
    jobs:
    - build:
        name: "build 1.23.1"
        build-image: "datadog/docker-library:nginx-datadog-build-1.23.1"
        nginx-tag: "1.23.1"
    - test:
        name: "test 1.23.1"
        requires:
        - "build 1.23.1"
    - build:
        name: "build 1.23.1-alpine"
        build-image: "datadog/docker-library:nginx-datadog-build-1.23.1-alpine"
        nginx-tag: "1.23.1-alpine"
    - test:
        name: "test 1.23.1-alpine"
        requires:
        - "build 1.23.1-alpine"
